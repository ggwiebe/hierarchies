{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc2950bf-233e-4677-bdeb-cea16eb15bf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configure - Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea9086f-884f-4c18-a55d-d6f6d8dcac17",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use catalog and schema"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_catalog()</th><th>current_schema()</th></tr></thead><tbody><tr><td>ggw</td><td>hr</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ggw",
         "hr"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_catalog()",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_schema()",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG ggw;\n",
    "USE SCHEMA hr;\n",
    "\n",
    "SELECT current_catalog(), current_database();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "832f84a7-fbf5-4f09-acf9-e05c8cea8253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configure - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea34c87-a4e4-4606-8a67-a7b4c32d15da",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Table"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 131
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE Employees (\n",
    "    EmployeeID INT PRIMARY KEY,\n",
    "    Name VARCHAR(100),\n",
    "    ManagerID INT,\n",
    "    ManagementHierarchy STRING\n",
    ");\n",
    "\n",
    "SELECT *\n",
    "  FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1c763d-e0da-4e0e-8fbc-6fba1a9fc7ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize table with data"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1"
        ],
        [
         3,
         "Charlie",
         1,
         "1"
        ],
        [
         4,
         "David",
         2,
         "2"
        ],
        [
         5,
         "Eve",
         2,
         "2"
        ],
        [
         6,
         "Frank",
         3,
         "3"
        ],
        [
         7,
         "Grace",
         3,
         "3"
        ],
        [
         8,
         "Hank",
         4,
         "4"
        ],
        [
         9,
         "Ivy",
         4,
         "4"
        ],
        [
         10,
         "Jack",
         5,
         "5"
        ],
        [
         11,
         "Karen",
         5,
         "5"
        ],
        [
         12,
         "Leo",
         6,
         "6"
        ],
        [
         13,
         "Mona",
         6,
         "6"
        ],
        [
         14,
         "Nina",
         7,
         "7"
        ],
        [
         15,
         "Oscar",
         7,
         "7"
        ],
        [
         16,
         "Paul",
         8,
         "8"
        ],
        [
         17,
         "Quinn",
         8,
         "8"
        ],
        [
         18,
         "Rose",
         9,
         "9"
        ],
        [
         19,
         "Steve",
         9,
         "9"
        ],
        [
         20,
         "Tina",
         10,
         "10"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"EmployeeID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"ManagerID\", IntegerType(), True),\n",
    "    StructField(\"ManagementHierarchy\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create sample data for the Employees table\n",
    "data = [\n",
    "    # (1, 'Alice', None),\n",
    "    (1, 'Alice', 0, None),\n",
    "    (2, 'Bob', 1, 1),\n",
    "    (3, 'Charlie', 1, 1),\n",
    "    (4, 'David', 2, 2),\n",
    "    (5, 'Eve', 2, 2),\n",
    "    (6, 'Frank', 3, 3),\n",
    "    (7, 'Grace', 3, 3),\n",
    "    (8, 'Hank', 4, 4),\n",
    "    (9, 'Ivy', 4, 4),\n",
    "    (10, 'Jack', 5, 5),\n",
    "    (11, 'Karen', 5, 5),\n",
    "    (12, 'Leo', 6, 6),\n",
    "    (13, 'Mona', 6, 6),\n",
    "    (14, 'Nina', 7, 7),\n",
    "    (15, 'Oscar', 7, 7),\n",
    "    (16, 'Paul', 8, 8),\n",
    "    (17, 'Quinn', 8, 8),\n",
    "    (18, 'Rose', 9, 9),\n",
    "    (19, 'Steve', 9, 9),\n",
    "    (20, 'Tina', 10, 10)\n",
    "]\n",
    "\n",
    "# Create a Spark DataFrame using the schema\n",
    "spark_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Display the sample data\n",
    "display(spark_df)\n",
    "\n",
    "# Create the table schema\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS employees (\n",
    "    EmployeeID INT,\n",
    "    Name STRING,\n",
    "    ManagerID INT,\n",
    "    ManagementHierarchy STRING\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Save the Spark DataFrame as a table with overwrite mode\n",
    "# spark_df.write.mode('append').saveAsTable('employees')\n",
    "spark_df.write.mode('overwrite').saveAsTable('employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d797b4f-e5eb-4490-8ab9-07285365a88b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Management Hierarchy Logic  \n",
    "  \n",
    "1. Self-join to employee (alias \"Manager\")\n",
    "2. If the Last Management Hierarchy ManagerID was Top/\"0\" then stop (i.e. only repeat for non-0 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a18b5cf9-03e9-4d7b-a4ca-051f4fec1136",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query the hierarchy when not at top"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>LastHierarchyManagerID</th><th>ManagersManagerID</th></tr></thead><tbody><tr><td>4</td><td>David</td><td>2</td><td>2</td><td>2</td><td>1</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2</td><td>2</td><td>1</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3</td><td>3</td><td>1</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3</td><td>3</td><td>1</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4</td><td>4</td><td>2</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4</td><td>4</td><td>2</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5</td><td>5</td><td>2</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5</td><td>5</td><td>2</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6</td><td>6</td><td>3</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6</td><td>6</td><td>3</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7</td><td>7</td><td>3</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7</td><td>7</td><td>3</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8</td><td>8</td><td>4</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8</td><td>8</td><td>4</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9</td><td>9</td><td>4</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9</td><td>9</td><td>4</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10</td><td>10</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         "David",
         2,
         "2",
         "2",
         1
        ],
        [
         5,
         "Eve",
         2,
         "2",
         "2",
         1
        ],
        [
         6,
         "Frank",
         3,
         "3",
         "3",
         1
        ],
        [
         7,
         "Grace",
         3,
         "3",
         "3",
         1
        ],
        [
         8,
         "Hank",
         4,
         "4",
         "4",
         2
        ],
        [
         9,
         "Ivy",
         4,
         "4",
         "4",
         2
        ],
        [
         10,
         "Jack",
         5,
         "5",
         "5",
         2
        ],
        [
         11,
         "Karen",
         5,
         "5",
         "5",
         2
        ],
        [
         12,
         "Leo",
         6,
         "6",
         "6",
         3
        ],
        [
         13,
         "Mona",
         6,
         "6",
         "6",
         3
        ],
        [
         14,
         "Nina",
         7,
         "7",
         "7",
         3
        ],
        [
         15,
         "Oscar",
         7,
         "7",
         "7",
         3
        ],
        [
         16,
         "Paul",
         8,
         "8",
         "8",
         4
        ],
        [
         17,
         "Quinn",
         8,
         "8",
         "8",
         4
        ],
        [
         18,
         "Rose",
         9,
         "9",
         "9",
         4
        ],
        [
         19,
         "Steve",
         9,
         "9",
         "9",
         4
        ],
        [
         20,
         "Tina",
         10,
         "10",
         "10",
         5
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "LastHierarchyManagerID",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagersManagerID",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 77
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastHierarchyManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagersManagerID",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT e.*,\n",
    "       SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "       m.ManagerID AS ManagersManagerID\n",
    "  FROM employees e\n",
    "  JOIN employees m ON SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] = m.EmployeeID\n",
    " WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    " ORDER BY e.EmployeeID ASC\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c0d80419-51cf-4c17-a77a-72f8d1936b45",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "For those rows, merge the next ancestry level"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1"
        ],
        [
         3,
         "Charlie",
         1,
         "1"
        ],
        [
         4,
         "David",
         2,
         "2-1"
        ],
        [
         5,
         "Eve",
         2,
         "2-1"
        ],
        [
         6,
         "Frank",
         3,
         "3-1"
        ],
        [
         7,
         "Grace",
         3,
         "3-1"
        ],
        [
         8,
         "Hank",
         4,
         "4-2"
        ],
        [
         9,
         "Ivy",
         4,
         "4-2"
        ],
        [
         10,
         "Jack",
         5,
         "5-2"
        ],
        [
         11,
         "Karen",
         5,
         "5-2"
        ],
        [
         12,
         "Leo",
         6,
         "6-3"
        ],
        [
         13,
         "Mona",
         6,
         "6-3"
        ],
        [
         14,
         "Nina",
         7,
         "7-3"
        ],
        [
         15,
         "Oscar",
         7,
         "7-3"
        ],
        [
         16,
         "Paul",
         8,
         "8-4"
        ],
        [
         17,
         "Quinn",
         8,
         "8-4"
        ],
        [
         18,
         "Rose",
         9,
         "9-4"
        ],
        [
         19,
         "Steve",
         9,
         "9-4"
        ],
        [
         20,
         "Tina",
         10,
         "10-5"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 56
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH EmployeeHierarchy AS (\n",
    "  SELECT e.EmployeeID,\n",
    "         e.ManagementHierarchy,\n",
    "         SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "         m.ManagerID AS ManagersManagerID\n",
    "    FROM employees e\n",
    "    JOIN employees m ON CAST(SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS INT) = m.EmployeeID\n",
    "   WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    ")\n",
    "MERGE INTO employees e\n",
    "USING EmployeeHierarchy eh\n",
    "ON e.EmployeeID = eh.EmployeeID\n",
    "WHEN MATCHED\n",
    "THEN UPDATE SET e.ManagementHierarchy = CONCAT(e.ManagementHierarchy, '-', COALESCE(eh.ManagersManagerID, '0'));\n",
    "\n",
    "SELECT *\n",
    "  FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "be7b4368-f02d-4ab7-8261-444b4df35471",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query for next ancestry level"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>LastHierarchyManagerID</th><th>ManagersManagerID</th></tr></thead><tbody><tr><td>8</td><td>Hank</td><td>4</td><td>4-2</td><td>2</td><td>1</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2</td><td>2</td><td>1</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2</td><td>2</td><td>1</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2</td><td>2</td><td>1</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3</td><td>3</td><td>1</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3</td><td>3</td><td>1</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3</td><td>3</td><td>1</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3</td><td>3</td><td>1</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4</td><td>4</td><td>2</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4</td><td>4</td><td>2</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4</td><td>4</td><td>2</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4</td><td>4</td><td>2</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5</td><td>5</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         8,
         "Hank",
         4,
         "4-2",
         "2",
         1
        ],
        [
         9,
         "Ivy",
         4,
         "4-2",
         "2",
         1
        ],
        [
         10,
         "Jack",
         5,
         "5-2",
         "2",
         1
        ],
        [
         11,
         "Karen",
         5,
         "5-2",
         "2",
         1
        ],
        [
         12,
         "Leo",
         6,
         "6-3",
         "3",
         1
        ],
        [
         13,
         "Mona",
         6,
         "6-3",
         "3",
         1
        ],
        [
         14,
         "Nina",
         7,
         "7-3",
         "3",
         1
        ],
        [
         15,
         "Oscar",
         7,
         "7-3",
         "3",
         1
        ],
        [
         16,
         "Paul",
         8,
         "8-4",
         "4",
         2
        ],
        [
         17,
         "Quinn",
         8,
         "8-4",
         "4",
         2
        ],
        [
         18,
         "Rose",
         9,
         "9-4",
         "4",
         2
        ],
        [
         19,
         "Steve",
         9,
         "9-4",
         "4",
         2
        ],
        [
         20,
         "Tina",
         10,
         "10-5",
         "5",
         2
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "LastHierarchyManagerID",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagersManagerID",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 58
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastHierarchyManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagersManagerID",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT e.*,\n",
    "       SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "       m.ManagerID AS ManagersManagerID\n",
    "  FROM employees e\n",
    "  JOIN employees m ON SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] = m.EmployeeID\n",
    " WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    " ORDER BY e.EmployeeID ASC\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a4ac8db0-60f0-4623-89a7-b0c1fd99f124",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "merge to level 3"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2-1</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2-1</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2-1</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2-1</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3-1</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3-1</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3-1</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3-1</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4-2</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4-2</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4-2</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4-2</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5-2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1"
        ],
        [
         3,
         "Charlie",
         1,
         "1"
        ],
        [
         4,
         "David",
         2,
         "2-1"
        ],
        [
         5,
         "Eve",
         2,
         "2-1"
        ],
        [
         6,
         "Frank",
         3,
         "3-1"
        ],
        [
         7,
         "Grace",
         3,
         "3-1"
        ],
        [
         8,
         "Hank",
         4,
         "4-2-1"
        ],
        [
         9,
         "Ivy",
         4,
         "4-2-1"
        ],
        [
         10,
         "Jack",
         5,
         "5-2-1"
        ],
        [
         11,
         "Karen",
         5,
         "5-2-1"
        ],
        [
         12,
         "Leo",
         6,
         "6-3-1"
        ],
        [
         13,
         "Mona",
         6,
         "6-3-1"
        ],
        [
         14,
         "Nina",
         7,
         "7-3-1"
        ],
        [
         15,
         "Oscar",
         7,
         "7-3-1"
        ],
        [
         16,
         "Paul",
         8,
         "8-4-2"
        ],
        [
         17,
         "Quinn",
         8,
         "8-4-2"
        ],
        [
         18,
         "Rose",
         9,
         "9-4-2"
        ],
        [
         19,
         "Steve",
         9,
         "9-4-2"
        ],
        [
         20,
         "Tina",
         10,
         "10-5-2"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 59
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH EmployeeHierarchy AS (\n",
    "  SELECT e.EmployeeID,\n",
    "         e.ManagementHierarchy,\n",
    "         SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "         m.ManagerID AS ManagersManagerID\n",
    "    FROM employees e\n",
    "    JOIN employees m ON CAST(SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS INT) = m.EmployeeID\n",
    "   WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    ")\n",
    "MERGE INTO employees e\n",
    "USING EmployeeHierarchy eh\n",
    "ON e.EmployeeID = eh.EmployeeID\n",
    "WHEN MATCHED\n",
    "THEN UPDATE SET e.ManagementHierarchy = CONCAT(e.ManagementHierarchy, '-', COALESCE(eh.ManagersManagerID, '0'));\n",
    "\n",
    "SELECT *\n",
    "  FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "002f95fc-0c62-483a-83a7-078cdb401c6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "merge to level 4"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2-1</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2-1</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2-1</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2-1</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3-1</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3-1</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3-1</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3-1</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4-2-1</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4-2-1</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4-2-1</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4-2-1</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5-2-1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1"
        ],
        [
         3,
         "Charlie",
         1,
         "1"
        ],
        [
         4,
         "David",
         2,
         "2-1"
        ],
        [
         5,
         "Eve",
         2,
         "2-1"
        ],
        [
         6,
         "Frank",
         3,
         "3-1"
        ],
        [
         7,
         "Grace",
         3,
         "3-1"
        ],
        [
         8,
         "Hank",
         4,
         "4-2-1"
        ],
        [
         9,
         "Ivy",
         4,
         "4-2-1"
        ],
        [
         10,
         "Jack",
         5,
         "5-2-1"
        ],
        [
         11,
         "Karen",
         5,
         "5-2-1"
        ],
        [
         12,
         "Leo",
         6,
         "6-3-1"
        ],
        [
         13,
         "Mona",
         6,
         "6-3-1"
        ],
        [
         14,
         "Nina",
         7,
         "7-3-1"
        ],
        [
         15,
         "Oscar",
         7,
         "7-3-1"
        ],
        [
         16,
         "Paul",
         8,
         "8-4-2-1"
        ],
        [
         17,
         "Quinn",
         8,
         "8-4-2-1"
        ],
        [
         18,
         "Rose",
         9,
         "9-4-2-1"
        ],
        [
         19,
         "Steve",
         9,
         "9-4-2-1"
        ],
        [
         20,
         "Tina",
         10,
         "10-5-2-1"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 60
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH EmployeeHierarchy AS (\n",
    "  SELECT e.EmployeeID,\n",
    "         e.ManagementHierarchy,\n",
    "         SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "         m.ManagerID AS ManagersManagerID\n",
    "    FROM employees e\n",
    "    JOIN employees m ON CAST(SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS INT) = m.EmployeeID\n",
    "   WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    ")\n",
    "MERGE INTO employees e\n",
    "USING EmployeeHierarchy eh\n",
    "ON e.EmployeeID = eh.EmployeeID\n",
    "WHEN MATCHED\n",
    "THEN UPDATE SET e.ManagementHierarchy = CONCAT(e.ManagementHierarchy, '-', COALESCE(eh.ManagersManagerID, '0'));\n",
    "\n",
    "SELECT *\n",
    "  FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "66fec86e-d270-421e-b4c1-2315910967d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Done all levels - show check is empty"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>LastHierarchyManagerID</th><th>ManagersManagerID</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "LastHierarchyManagerID",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagersManagerID",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 64
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastHierarchyManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagersManagerID",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT e.*,\n",
    "       SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "       m.ManagerID AS ManagersManagerID\n",
    "  FROM employees e\n",
    "  LEFT OUTER JOIN employees m ON SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] = m.EmployeeID\n",
    " WHERE SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] != 1\n",
    " ORDER BY e.EmployeeID ASC\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85153121-41e8-4905-9874-464f8a04863d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Re-write the above pattern in a single loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8faa2dc7-4cd3-49ff-97fe-e4652b378e32",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "While more ancestors - merge to hierarchy"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows inserted: 0; Rows updated: 17; Rows deleted: 0\nRows inserted: 0; Rows updated: 13; Rows deleted: 0\nRows inserted: 0; Rows updated: 5; Rows deleted: 0\nRows inserted: 0; Rows updated: 0; Rows deleted: 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>HierarchySize</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td><td>2</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td><td>2</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td><td>2</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td><td>2</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2-1</td><td>3</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2-1</td><td>3</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2-1</td><td>3</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2-1</td><td>3</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3-1</td><td>3</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3-1</td><td>3</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3-1</td><td>3</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3-1</td><td>3</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4-2-1</td><td>4</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4-2-1</td><td>4</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4-2-1</td><td>4</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4-2-1</td><td>4</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5-2-1</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1",
         1
        ],
        [
         3,
         "Charlie",
         1,
         "1",
         1
        ],
        [
         4,
         "David",
         2,
         "2-1",
         2
        ],
        [
         5,
         "Eve",
         2,
         "2-1",
         2
        ],
        [
         6,
         "Frank",
         3,
         "3-1",
         2
        ],
        [
         7,
         "Grace",
         3,
         "3-1",
         2
        ],
        [
         8,
         "Hank",
         4,
         "4-2-1",
         3
        ],
        [
         9,
         "Ivy",
         4,
         "4-2-1",
         3
        ],
        [
         10,
         "Jack",
         5,
         "5-2-1",
         3
        ],
        [
         11,
         "Karen",
         5,
         "5-2-1",
         3
        ],
        [
         12,
         "Leo",
         6,
         "6-3-1",
         3
        ],
        [
         13,
         "Mona",
         6,
         "6-3-1",
         3
        ],
        [
         14,
         "Nina",
         7,
         "7-3-1",
         3
        ],
        [
         15,
         "Oscar",
         7,
         "7-3-1",
         3
        ],
        [
         16,
         "Paul",
         8,
         "8-4-2-1",
         4
        ],
        [
         17,
         "Quinn",
         8,
         "8-4-2-1",
         4
        ],
        [
         18,
         "Rose",
         9,
         "9-4-2-1",
         4
        ],
        [
         19,
         "Steve",
         9,
         "9-4-2-1",
         4
        ],
        [
         20,
         "Tina",
         10,
         "10-5-2-1",
         4
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "HierarchySize",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "# Reference to the Delta table\n",
    "empTable = DeltaTable.forName(spark, \"employees\")\n",
    "\n",
    "rows_updated = 1\n",
    "\n",
    "while rows_updated > 0:\n",
    "    result = spark.sql(\"\"\"\n",
    "    WITH EmployeeHierarchy AS (\n",
    "      SELECT e.EmployeeID,\n",
    "             e.ManagementHierarchy,\n",
    "             SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS LastHierarchyManagerID,\n",
    "             m.ManagerID AS ManagersManagerID\n",
    "        FROM employees e\n",
    "        JOIN employees m ON CAST(SPLIT(e.ManagementHierarchy, '-')[SIZE(SPLIT(e.ManagementHierarchy, '-')) - 1] AS INT) = m.EmployeeID\n",
    "       WHERE m.ManagerID != 0 -- Don't update if you are the top already\n",
    "    )\n",
    "    MERGE INTO employees e\n",
    "    USING EmployeeHierarchy eh\n",
    "    ON e.EmployeeID = eh.EmployeeID\n",
    "    WHEN MATCHED\n",
    "    THEN UPDATE SET e.ManagementHierarchy = CONCAT(e.ManagementHierarchy, '-', COALESCE(eh.ManagersManagerID, '0'))\n",
    "    \"\"\")\n",
    "    \n",
    "    # result.count() does not work with merge!!! See below\n",
    "    # merge_count = result.count()\n",
    "    # print(f\"Rows updated via merge: {merge_count}\")\n",
    "\n",
    "    # Get the history of the table\n",
    "    history = empTable.history()\n",
    "    # Get latest merge results from the history table\n",
    "    latest_operation = history.select(\"operationMetrics\").limit(1).collect()[0][0]\n",
    "    # Extract the row counts from the history\n",
    "    rows_inserted = int(latest_operation[\"numTargetRowsInserted\"])\n",
    "    rows_updated = int(latest_operation[\"numTargetRowsUpdated\"])\n",
    "    rows_deleted = int(latest_operation[\"numTargetRowsDeleted\"])\n",
    "\n",
    "    print(f\"Rows inserted: {rows_inserted}; Rows updated: {rows_updated}; Rows deleted: {rows_deleted}\")\n",
    "\n",
    "display(spark.sql(\"SELECT *, SIZE(SPLIT(ManagementHierarchy, '-')) AS HierarchySize FROM employees\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2a5e85-a2ee-4175-88ef-6bcb7db0cd93",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check results including depth"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>HierarchySize</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td><td>null</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td><td>1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td><td>1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td><td>2</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td><td>2</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td><td>2</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td><td>2</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2-1</td><td>3</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2-1</td><td>3</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2-1</td><td>3</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2-1</td><td>3</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3-1</td><td>3</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3-1</td><td>3</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3-1</td><td>3</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3-1</td><td>3</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4-2-1</td><td>4</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4-2-1</td><td>4</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4-2-1</td><td>4</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4-2-1</td><td>4</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5-2-1</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null,
         null
        ],
        [
         2,
         "Bob",
         1,
         "1",
         1
        ],
        [
         3,
         "Charlie",
         1,
         "1",
         1
        ],
        [
         4,
         "David",
         2,
         "2-1",
         2
        ],
        [
         5,
         "Eve",
         2,
         "2-1",
         2
        ],
        [
         6,
         "Frank",
         3,
         "3-1",
         2
        ],
        [
         7,
         "Grace",
         3,
         "3-1",
         2
        ],
        [
         8,
         "Hank",
         4,
         "4-2-1",
         3
        ],
        [
         9,
         "Ivy",
         4,
         "4-2-1",
         3
        ],
        [
         10,
         "Jack",
         5,
         "5-2-1",
         3
        ],
        [
         11,
         "Karen",
         5,
         "5-2-1",
         3
        ],
        [
         12,
         "Leo",
         6,
         "6-3-1",
         3
        ],
        [
         13,
         "Mona",
         6,
         "6-3-1",
         3
        ],
        [
         14,
         "Nina",
         7,
         "7-3-1",
         3
        ],
        [
         15,
         "Oscar",
         7,
         "7-3-1",
         3
        ],
        [
         16,
         "Paul",
         8,
         "8-4-2-1",
         4
        ],
        [
         17,
         "Quinn",
         8,
         "8-4-2-1",
         4
        ],
        [
         18,
         "Rose",
         9,
         "9-4-2-1",
         4
        ],
        [
         19,
         "Steve",
         9,
         "9-4-2-1",
         4
        ],
        [
         20,
         "Tina",
         10,
         "10-5-2-1",
         4
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "HierarchySize",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 103
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "HierarchySize",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *,\n",
    "       SIZE(SPLIT(ManagementHierarchy, '-')) AS HierarchySize\n",
    "  FROM employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87b14430-0c20-40c5-8d7e-368b72e94e13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57799eea-2c7c-4c06-b95e-86506a45c099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f37c2150-5c5d-4a01-9424-9886d2e98fbe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Static 4 Level Hierarchy Query"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>ManagerID</th><th>ManagementHierarchy</th><th>L1_ManagerName</th><th>L1_ManagerID</th><th>L2_ManagerName</th><th>L2_ManagerID</th><th>L3_ManagerName</th><th>L3_ManagerID</th><th>L4_ManagerName</th><th>L4_ManagerID</th><th>ManagerHierarchy</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>0</td><td>null</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-0-0</td></tr><tr><td>2</td><td>Bob</td><td>1</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-0-1</td></tr><tr><td>3</td><td>Charlie</td><td>1</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-0-1</td></tr><tr><td>4</td><td>David</td><td>2</td><td>2-1</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-1-2</td></tr><tr><td>5</td><td>Eve</td><td>2</td><td>2-1</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-1-2</td></tr><tr><td>6</td><td>Frank</td><td>3</td><td>3-1</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-1-3</td></tr><tr><td>7</td><td>Grace</td><td>3</td><td>3-1</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>Top</td><td>0</td><td>0-0-0-1-3</td></tr><tr><td>8</td><td>Hank</td><td>4</td><td>4-2-1</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-2-4</td></tr><tr><td>9</td><td>Ivy</td><td>4</td><td>4-2-1</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-2-4</td></tr><tr><td>10</td><td>Jack</td><td>5</td><td>5-2-1</td><td>Eve</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-2-5</td></tr><tr><td>11</td><td>Karen</td><td>5</td><td>5-2-1</td><td>Eve</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-2-5</td></tr><tr><td>12</td><td>Leo</td><td>6</td><td>6-3-1</td><td>Frank</td><td>3</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-3-6</td></tr><tr><td>13</td><td>Mona</td><td>6</td><td>6-3-1</td><td>Frank</td><td>3</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-3-6</td></tr><tr><td>14</td><td>Nina</td><td>7</td><td>7-3-1</td><td>Grace</td><td>3</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-3-7</td></tr><tr><td>15</td><td>Oscar</td><td>7</td><td>7-3-1</td><td>Grace</td><td>3</td><td>Charlie</td><td>1</td><td>Alice</td><td>0</td><td>Top</td><td>0</td><td>0-0-1-3-7</td></tr><tr><td>16</td><td>Paul</td><td>8</td><td>8-4-2-1</td><td>Hank</td><td>4</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>0-1-2-4-8</td></tr><tr><td>17</td><td>Quinn</td><td>8</td><td>8-4-2-1</td><td>Hank</td><td>4</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>0-1-2-4-8</td></tr><tr><td>18</td><td>Rose</td><td>9</td><td>9-4-2-1</td><td>Ivy</td><td>4</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>0-1-2-4-9</td></tr><tr><td>19</td><td>Steve</td><td>9</td><td>9-4-2-1</td><td>Ivy</td><td>4</td><td>David</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>0-1-2-4-9</td></tr><tr><td>20</td><td>Tina</td><td>10</td><td>10-5-2-1</td><td>Jack</td><td>5</td><td>Eve</td><td>2</td><td>Bob</td><td>1</td><td>Alice</td><td>0</td><td>0-1-2-5-10</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         0,
         null,
         "Top",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-0-0"
        ],
        [
         2,
         "Bob",
         1,
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-0-1"
        ],
        [
         3,
         "Charlie",
         1,
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-0-1"
        ],
        [
         4,
         "David",
         2,
         "2-1",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-1-2"
        ],
        [
         5,
         "Eve",
         2,
         "2-1",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-1-2"
        ],
        [
         6,
         "Frank",
         3,
         "3-1",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-1-3"
        ],
        [
         7,
         "Grace",
         3,
         "3-1",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "Top",
         "0",
         "0-0-0-1-3"
        ],
        [
         8,
         "Hank",
         4,
         "4-2-1",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-2-4"
        ],
        [
         9,
         "Ivy",
         4,
         "4-2-1",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-2-4"
        ],
        [
         10,
         "Jack",
         5,
         "5-2-1",
         "Eve",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-2-5"
        ],
        [
         11,
         "Karen",
         5,
         "5-2-1",
         "Eve",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-2-5"
        ],
        [
         12,
         "Leo",
         6,
         "6-3-1",
         "Frank",
         "3",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-3-6"
        ],
        [
         13,
         "Mona",
         6,
         "6-3-1",
         "Frank",
         "3",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-3-6"
        ],
        [
         14,
         "Nina",
         7,
         "7-3-1",
         "Grace",
         "3",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-3-7"
        ],
        [
         15,
         "Oscar",
         7,
         "7-3-1",
         "Grace",
         "3",
         "Charlie",
         "1",
         "Alice",
         "0",
         "Top",
         "0",
         "0-0-1-3-7"
        ],
        [
         16,
         "Paul",
         8,
         "8-4-2-1",
         "Hank",
         "4",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "0-1-2-4-8"
        ],
        [
         17,
         "Quinn",
         8,
         "8-4-2-1",
         "Hank",
         "4",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "0-1-2-4-8"
        ],
        [
         18,
         "Rose",
         9,
         "9-4-2-1",
         "Ivy",
         "4",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "0-1-2-4-9"
        ],
        [
         19,
         "Steve",
         9,
         "9-4-2-1",
         "Ivy",
         "4",
         "David",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "0-1-2-4-9"
        ],
        [
         20,
         "Tina",
         10,
         "10-5-2-1",
         "Jack",
         "5",
         "Eve",
         "2",
         "Bob",
         "1",
         "Alice",
         "0",
         "0-1-2-5-10"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "EmployeeID",
            "nullable": false,
            "type": "integer"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(100)"
            },
            "name": "Name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "ManagementHierarchy",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L1_ManagerName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L1_ManagerID",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L2_ManagerName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L2_ManagerID",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L3_ManagerName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L3_ManagerID",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L4_ManagerName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "L4_ManagerID",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ManagerHierarchy",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 96
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(100)\"}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ManagementHierarchy",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L1_ManagerName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L1_ManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L2_ManagerName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L2_ManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L3_ManagerName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L3_ManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L4_ManagerName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "L4_ManagerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ManagerHierarchy",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "        --  CASE \n",
    "        --    WHEN l4.ManagerID IS NULL THEN '0' \n",
    "        --    ELSE CAST(l4.ManagerID AS STRING) \n",
    "        --  END,\n",
    "        --  '-',\n",
    "        --  CASE \n",
    "        --    WHEN l3.ManagerID IS NULL THEN '0' \n",
    "        --    ELSE CAST(l3.ManagerID AS STRING) \n",
    "        --  END,\n",
    "        --  '-',\n",
    "        --  CASE \n",
    "        --    WHEN l2.ManagerID IS NULL THEN '0' \n",
    "        --    ELSE CAST(l2.ManagerID AS STRING) \n",
    "        --  END,\n",
    "        --  '-',\n",
    "        --  CASE \n",
    "        --    WHEN l1.ManagerID IS NULL THEN '0' \n",
    "        --    ELSE CAST(l1.ManagerID AS STRING) \n",
    "        --  END,\n",
    "        --  '-',\n",
    "        --  CAST(e.ManagerID AS STRING)\n",
    "\n",
    "SELECT e.*, -- EXCEPT (ManagementHierarchy), <== This is the right answer, so hide\n",
    "      --  l1.Name AS L1_ManagerName,\n",
    "      --  l1.ManagerID AS L1_ManagerID,\n",
    "       CASE \n",
    "         WHEN l1.Name IS NULL THEN 'Top' \n",
    "         ELSE l1.Name\n",
    "       END AS L1_ManagerName,\n",
    "       CASE \n",
    "         WHEN l1.ManagerID IS NULL THEN '0' \n",
    "         ELSE CAST(l1.ManagerID AS STRING) \n",
    "       END AS L1_ManagerID,\n",
    "      --  l2.Name AS L2_ManagerName,\n",
    "      --  l2.ManagerID AS L2_ManagerID,\n",
    "       CASE \n",
    "         WHEN l2.Name IS NULL THEN 'Top' \n",
    "         ELSE l2.Name\n",
    "       END AS L2_ManagerName,\n",
    "       CASE \n",
    "         WHEN l2.ManagerID IS NULL THEN '0' \n",
    "         ELSE CAST(l2.ManagerID AS STRING) \n",
    "       END AS L2_ManagerID,\n",
    "      --  l3.Name AS L3_ManagerName,\n",
    "      --  l3.ManagerID AS L3_ManagerID,\n",
    "       CASE \n",
    "         WHEN l3.Name IS NULL THEN 'Top' \n",
    "         ELSE l3.Name\n",
    "       END AS L3_ManagerName,\n",
    "       CASE \n",
    "         WHEN l3.ManagerID IS NULL THEN '0' \n",
    "         ELSE CAST(l3.ManagerID AS STRING) \n",
    "       END AS L3_ManagerID,\n",
    "      --  l4.Name AS L4_ManagerName,\n",
    "      --  l4.ManagerID AS L4_ManagerID,\n",
    "       CASE \n",
    "         WHEN l4.Name IS NULL THEN 'Top' \n",
    "         ELSE l4.Name\n",
    "       END AS L4_ManagerName,\n",
    "       CASE \n",
    "         WHEN l4.ManagerID IS NULL THEN '0' \n",
    "         ELSE CAST(l4.ManagerID AS STRING) \n",
    "       END AS L4_ManagerID,\n",
    "       CONCAT(\n",
    "         L4_ManagerID,\n",
    "         '-',\n",
    "         L3_ManagerID,\n",
    "         '-',\n",
    "         L2_ManagerID,\n",
    "         '-',\n",
    "         L1_ManagerID,\n",
    "         '-',\n",
    "         CAST(e.ManagerID AS STRING)\n",
    "       ) AS ManagerHierarchy\n",
    "  FROM employees e\n",
    "  LEFT OUTER JOIN employees l1\n",
    "    ON l1.EmployeeID = e.ManagerID\n",
    "  LEFT OUTER JOIN employees l2\n",
    "    ON l2.EmployeeID = l1.ManagerID\n",
    "  LEFT OUTER JOIN employees l3\n",
    "    ON l3.EmployeeID = l2.ManagerID\n",
    "  LEFT OUTER JOIN employees l4\n",
    "    ON l4.EmployeeID = l3.ManagerID\n",
    "--  ORDER BY ManagerHierarchy ASC\n",
    " ORDER BY e.EmployeeID ASC\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81518f82-127f-4c03-b602-ea9eb564b77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### GraphFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dedfef8-c1a8-4de2-94b7-00590d4ad584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting graphframes\n",
       "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
       "Requirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from graphframes) (1.20.1)\n",
       "Collecting nose\n",
       "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
       "Installing collected packages: nose, graphframes\n",
       "Successfully installed graphframes-0.6 nose-1.3.7\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting graphframes\n  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from graphframes) (1.20.1)\nCollecting nose\n  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\nInstalling collected packages: nose, graphframes\nSuccessfully installed graphframes-0.6 nose-1.3.7\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install the GraphFrames library\n",
    "%pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbcdd78c-b860-4b04-a584-735d3d332d87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c53b1ca6-9d12-47a5-b860-be31ecce35c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_catalog()</th><th>current_database()</th><th>current_timestamp()</th></tr></thead><tbody><tr><td>ggw</td><td>hr</td><td>2025-01-31T16:34:07.124+0000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ggw",
         "hr",
         "2025-01-31T16:34:07.124+0000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_catalog()",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_database()",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_timestamp()",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG ggw;\n",
    "USE SCHEMA hr;\n",
    "\n",
    "SELECT current_catalog(), current_database(), current_timestamp();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc41c906-483d-4230-9778-848240a9b39f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-971429592434143&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>employees_df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>table<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;employees&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> managers_df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;SELECT EmployeeID, ManagerID, &#39;Manager&#39; AS Relationship FROM employees WHERE ManagerID IS NOT NULL&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> display<span class=\"ansi-blue-fg\">(</span>managers_df<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">table</span><span class=\"ansi-blue-fg\">(self, tableName)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    793</span>         <span class=\"ansi-green-fg\">True</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    794</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 795</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>table<span class=\"ansi-blue-fg\">(</span>tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    796</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    797</span>     <span class=\"ansi-blue-fg\">@</span>property\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: `default`.`employees` is not a Delta table.</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-971429592434143&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>employees_df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>table<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;employees&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> managers_df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;SELECT EmployeeID, ManagerID, &#39;Manager&#39; AS Relationship FROM employees WHERE ManagerID IS NOT NULL&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> display<span class=\"ansi-blue-fg\">(</span>managers_df<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">table</span><span class=\"ansi-blue-fg\">(self, tableName)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    793</span>         <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    794</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 795</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>table<span class=\"ansi-blue-fg\">(</span>tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    796</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    797</span>     <span class=\"ansi-blue-fg\">@</span>property\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: `default`.`employees` is not a Delta table.</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: `default`.`employees` is not a Delta table.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "employees_df = spark.table(\"employees\")\n",
    "managers_df = spark.sql(\"SELECT EmployeeID, ManagerID, 'Manager' AS Relationship FROM employees WHERE ManagerID IS NOT NULL\")\n",
    "\n",
    "display(managers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ee2ae4-535f-481f-917a-6ecfd26d5917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPySparkTypeError\u001B[0m                          Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-971429592434590>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Create a GraphFrame\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(v\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDataFrame(employees_df), e\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDataFrame(managers_df))\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Display Graph\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m display(g)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/connect/session.py:462\u001B[0m, in \u001B[0;36mSparkSession.createDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n",
       "\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, DataFrame):\n",
       "\u001B[0;32m--> 462\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m    463\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    464\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n",
       "\u001B[1;32m    465\u001B[0m     )\n",
       "\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m samplingRatio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    468\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msamplingRatio\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is ignored. It is not supported with Spark Connect.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mPySparkTypeError\u001B[0m: [INVALID_TYPE] Argument `data` should not be a DataFrame."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "PySparkTypeError",
        "evalue": "[INVALID_TYPE] Argument `data` should not be a DataFrame."
       },
       "metadata": {
        "errorSummary": "[INVALID_TYPE] Argument `data` should not be a DataFrame."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "INVALID_TYPE",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPySparkTypeError\u001B[0m                          Traceback (most recent call last)",
        "File \u001B[0;32m<command-971429592434590>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Create a GraphFrame\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(v\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDataFrame(employees_df), e\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDataFrame(managers_df))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Display Graph\u001B[39;00m\n\u001B[1;32m      7\u001B[0m display(g)\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/connect/session.py:462\u001B[0m, in \u001B[0;36mSparkSession.createDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, DataFrame):\n\u001B[0;32m--> 462\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m    463\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    464\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    465\u001B[0m     )\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m samplingRatio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    468\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msamplingRatio\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is ignored. It is not supported with Spark Connect.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "\u001B[0;31mPySparkTypeError\u001B[0m: [INVALID_TYPE] Argument `data` should not be a DataFrame."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v=employees_df, e=managers_df)\n",
    "\n",
    "# Display Graph\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d2f3222-cdca-44b7-862c-7735fe1cdbbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0177f73d-d975-40ac-b803-a602637fe9a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPySparkTypeError\u001B[0m                          Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-971429592433441>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Ensure employees_df and managers_df are Spark DataFrames\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m emp_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(employees_df)\n",
       "\u001B[1;32m      5\u001B[0m mgr_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(managers_df)\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Create a GraphFrame\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1560\u001B[0m, in \u001B[0;36mSparkSession.createDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n",
       "\u001B[1;32m   1558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39mSparkSession\u001B[38;5;241m.\u001B[39msetActiveSession(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsparkSession)\n",
       "\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, DataFrame):\n",
       "\u001B[0;32m-> 1560\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m   1561\u001B[0m         errorClass\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1562\u001B[0m         messageParameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n",
       "\u001B[1;32m   1563\u001B[0m     )\n",
       "\u001B[1;32m   1565\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(schema, \u001B[38;5;28mstr\u001B[39m):\n",
       "\u001B[1;32m   1566\u001B[0m     schema \u001B[38;5;241m=\u001B[39m cast(Union[AtomicType, StructType, \u001B[38;5;28mstr\u001B[39m], _parse_datatype_string(schema))\n",
       "\n",
       "\u001B[0;31mPySparkTypeError\u001B[0m: [INVALID_TYPE] Argument `data` should not be a DataFrame."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "PySparkTypeError",
        "evalue": "[INVALID_TYPE] Argument `data` should not be a DataFrame."
       },
       "metadata": {
        "errorSummary": "[INVALID_TYPE] Argument `data` should not be a DataFrame."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "INVALID_TYPE",
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPySparkTypeError\u001B[0m                          Traceback (most recent call last)",
        "File \u001B[0;32m<command-971429592433441>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Ensure employees_df and managers_df are Spark DataFrames\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m emp_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(employees_df)\n\u001B[1;32m      5\u001B[0m mgr_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(managers_df)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Create a GraphFrame\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1560\u001B[0m, in \u001B[0;36mSparkSession.createDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39mSparkSession\u001B[38;5;241m.\u001B[39msetActiveSession(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsparkSession)\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, DataFrame):\n\u001B[0;32m-> 1560\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   1561\u001B[0m         errorClass\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1562\u001B[0m         messageParameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m   1563\u001B[0m     )\n\u001B[1;32m   1565\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(schema, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1566\u001B[0m     schema \u001B[38;5;241m=\u001B[39m cast(Union[AtomicType, StructType, \u001B[38;5;28mstr\u001B[39m], _parse_datatype_string(schema))\n",
        "\u001B[0;31mPySparkTypeError\u001B[0m: [INVALID_TYPE] Argument `data` should not be a DataFrame."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "# Ensure employees_df and managers_df are Spark DataFrames\n",
    "emp_df = spark.createDataFrame(employees_df)\n",
    "mgr_df = spark.createDataFrame(managers_df)\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v=employees_df, e=managers_df)\n",
    "\n",
    "# Display Graph\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "909e4b70-9c72-4ce4-9f26-ac95fc6e3993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPySparkAttributeError\u001B[0m                     Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-971429592434280>, line 10\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m edges \u001B[38;5;241m=\u001B[39m managers_df\u001B[38;5;241m.\u001B[39mwithColumnRenamed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmployeeID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msrc\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mwithColumnRenamed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mManagerID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdst\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Create the GraphFrame\u001B[39;00m\n",
       "\u001B[0;32m---> 10\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(vertices, edges)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b880d600-b475-472f-be3f-2d91d3097461/lib/python3.11/site-packages/graphframes/graphframe.py:63\u001B[0m, in \u001B[0;36mGraphFrame.__init__\u001B[0;34m(self, v, e)\u001B[0m\n",
       "\u001B[1;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vertices \u001B[38;5;241m=\u001B[39m v\n",
       "\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_edges \u001B[38;5;241m=\u001B[39m e\n",
       "\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m.\u001B[39msql_ctx\n",
       "\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext\u001B[38;5;241m.\u001B[39m_sc\n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm_gf_api \u001B[38;5;241m=\u001B[39m _java_api(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/dataframe.py:1821\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   1818\u001B[0m \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n",
       "\u001B[1;32m   1820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n",
       "\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkAttributeError(\n",
       "\u001B[1;32m   1822\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mATTRIBUTE_NOT_SUPPORTED\u001B[39m\u001B[38;5;124m\"\u001B[39m, message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattr_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: name}\n",
       "\u001B[1;32m   1823\u001B[0m     )\n",
       "\u001B[1;32m   1825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col(name)\n",
       "\n",
       "\u001B[0;31mPySparkAttributeError\u001B[0m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "PySparkAttributeError",
        "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       },
       "metadata": {
        "errorSummary": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "ATTRIBUTE_NOT_SUPPORTED",
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPySparkAttributeError\u001B[0m                     Traceback (most recent call last)",
        "File \u001B[0;32m<command-971429592434280>, line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m edges \u001B[38;5;241m=\u001B[39m managers_df\u001B[38;5;241m.\u001B[39mwithColumnRenamed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmployeeID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msrc\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mwithColumnRenamed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mManagerID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdst\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Create the GraphFrame\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(vertices, edges)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b880d600-b475-472f-be3f-2d91d3097461/lib/python3.11/site-packages/graphframes/graphframe.py:63\u001B[0m, in \u001B[0;36mGraphFrame.__init__\u001B[0;34m(self, v, e)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vertices \u001B[38;5;241m=\u001B[39m v\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_edges \u001B[38;5;241m=\u001B[39m e\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m.\u001B[39msql_ctx\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext\u001B[38;5;241m.\u001B[39m_sc\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm_gf_api \u001B[38;5;241m=\u001B[39m _java_api(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/dataframe.py:1821\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1818\u001B[0m \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n\u001B[1;32m   1820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkAttributeError(\n\u001B[1;32m   1822\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mATTRIBUTE_NOT_SUPPORTED\u001B[39m\u001B[38;5;124m\"\u001B[39m, message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattr_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: name}\n\u001B[1;32m   1823\u001B[0m     )\n\u001B[1;32m   1825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col(name)\n",
        "\u001B[0;31mPySparkAttributeError\u001B[0m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "# Create the vertices DataFrame\n",
    "vertices = employees_df.select(\"EmployeeID\").withColumnRenamed(\"EmployeeID\", \"id\")\n",
    "\n",
    "# Create the edges DataFrame\n",
    "edges = managers_df.withColumnRenamed(\"EmployeeID\", \"src\").withColumnRenamed(\"ManagerID\", \"dst\")\n",
    "\n",
    "# Create the GraphFrame\n",
    "g = GraphFrame(vertices, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c092212d-db8c-4ca6-8e74-7e3b41915425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2647fe08-78c9-4afa-bce7-8df3a1540ae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vertices = spark.createDataFrame([\n",
    "    (\"1\", \"Carter\", \"Derrick\", 50),\n",
    "    (\"2\", \"May\", \"Derrick\", 26),\n",
    "    # ... other vertices ...\n",
    "], [\"id\", \"name\", \"firstname\", \"age\"])\n",
    "\n",
    "edges = spark.createDataFrame([\n",
    "    (\"1\", \"2\", \"friend\"),\n",
    "    (\"2\", \"1\", \"friend\"),\n",
    "    # ... other edges ...\n",
    "], [\"src\", \"dst\", \"type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94cb5f6d-efb9-475c-a45b-34e02efb27b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPySparkAttributeError\u001B[0m                     Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-971429592434321>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n",
       "\u001B[0;32m----> 2\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(vertices, edges)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0436c599-57f3-41b2-9b5b-fad5881fb54b/lib/python3.11/site-packages/graphframes/graphframe.py:63\u001B[0m, in \u001B[0;36mGraphFrame.__init__\u001B[0;34m(self, v, e)\u001B[0m\n",
       "\u001B[1;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vertices \u001B[38;5;241m=\u001B[39m v\n",
       "\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_edges \u001B[38;5;241m=\u001B[39m e\n",
       "\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m.\u001B[39msql_ctx\n",
       "\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext\u001B[38;5;241m.\u001B[39m_sc\n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm_gf_api \u001B[38;5;241m=\u001B[39m _java_api(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/connect/dataframe.py:1821\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   1818\u001B[0m \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n",
       "\u001B[1;32m   1820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n",
       "\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkAttributeError(\n",
       "\u001B[1;32m   1822\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mATTRIBUTE_NOT_SUPPORTED\u001B[39m\u001B[38;5;124m\"\u001B[39m, message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattr_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: name}\n",
       "\u001B[1;32m   1823\u001B[0m     )\n",
       "\u001B[1;32m   1825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col(name)\n",
       "\n",
       "\u001B[0;31mPySparkAttributeError\u001B[0m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "PySparkAttributeError",
        "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       },
       "metadata": {
        "errorSummary": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "ATTRIBUTE_NOT_SUPPORTED",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPySparkAttributeError\u001B[0m                     Traceback (most recent call last)",
        "File \u001B[0;32m<command-971429592434321>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraphframes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphFrame\n\u001B[0;32m----> 2\u001B[0m g \u001B[38;5;241m=\u001B[39m GraphFrame(vertices, edges)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0436c599-57f3-41b2-9b5b-fad5881fb54b/lib/python3.11/site-packages/graphframes/graphframe.py:63\u001B[0m, in \u001B[0;36mGraphFrame.__init__\u001B[0;34m(self, v, e)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vertices \u001B[38;5;241m=\u001B[39m v\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_edges \u001B[38;5;241m=\u001B[39m e\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m.\u001B[39msql_ctx\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sqlContext\u001B[38;5;241m.\u001B[39m_sc\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm_gf_api \u001B[38;5;241m=\u001B[39m _java_api(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc)\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/connect/dataframe.py:1821\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1818\u001B[0m \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n\u001B[1;32m   1820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkAttributeError(\n\u001B[1;32m   1822\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mATTRIBUTE_NOT_SUPPORTED\u001B[39m\u001B[38;5;124m\"\u001B[39m, message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattr_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: name}\n\u001B[1;32m   1823\u001B[0m     )\n\u001B[1;32m   1825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_col(name)\n",
        "\u001B[0;31mPySparkAttributeError\u001B[0m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `sql_ctx` is not supported."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "g = GraphFrame(vertices, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe3440b8-db1e-461f-a5b7-21bd06d5aace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e9120b3-23b8-47e0-9510-37cdfe17b2be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform some graph operations\n",
    "print(\"In-degrees:\")\n",
    "g.inDegrees.show()\n",
    "\n",
    "print(\"Out-degrees:\")\n",
    "g.outDegrees.show()\n",
    "\n",
    "# Find the shortest paths from 'a' to all other vertices\n",
    "results = g.shortestPaths(landmarks=[\"a\"])\n",
    "print(\"Shortest paths from 'a':\")\n",
    "results.select(\"id\", \"distances\").show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 971429592434609,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Employee Hierarchies",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
